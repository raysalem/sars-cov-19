{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, urllib, re, math, json, requests\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# change plot size\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "# change max number of rows to show\n",
    "pd.set_option('display.max_rows', 300)\n",
    "\n",
    "try:\n",
    "    from packaging import version\n",
    "except ImportError:\n",
    "    !pip install packaging\n",
    "\n",
    "if( version.parse(pd.__version__) < version.parse(\"0.23.4\")):\n",
    "    print(\"update pandas\")\n",
    "    !pip install pandas --upgrade #--ignore-installed\n",
    "    print(version.parse(pd.__version__))\n",
    "#might need this\n",
    "#!pip install --upgrade pip    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "\n",
    "## plotters formats\n",
    "\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.dates as mdates\n",
    "from cycler import cycler\n",
    "\n",
    "myFmt = mdates.DateFormatter('%m/%d')\n",
    "myLocator = mticker.MultipleLocator(7)\n",
    "\n",
    "default_cycler = (cycler(marker=['.','*','+','s','x']) *\n",
    "                  cycler(color=['b','g','k','m','y','c','r']) *\n",
    "                  cycler(linestyle=['-']))\n",
    "\n",
    "plt.rc('axes', prop_cycle=default_cycler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# real time data, from a spin of JHU\n",
    "http://blog.lazd.net/coronadatascraper/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:979: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_nested_tuple(tup)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cases</th>\n",
       "      <th>death</th>\n",
       "      <th>recovered</th>\n",
       "      <th>tested</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">NaN</th>\n",
       "      <th rowspan=\"14\" valign=\"top\">NaN</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">NaN</th>\n",
       "      <th>Germany</th>\n",
       "      <td>3675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>17660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>5232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Switzerland</th>\n",
       "      <td>1139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hubei</th>\n",
       "      <th>China</th>\n",
       "      <td>67786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51553.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">NaN</th>\n",
       "      <th>Iran</th>\n",
       "      <td>11364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2959.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korea, South</th>\n",
       "      <td>7979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>510.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guangdong</th>\n",
       "      <th>China</th>\n",
       "      <td>1356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Henan</th>\n",
       "      <th>China</th>\n",
       "      <td>1273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zhejiang</th>\n",
       "      <th>China</th>\n",
       "      <td>1215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hunan</th>\n",
       "      <th>China</th>\n",
       "      <td>1018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilia Romagna</th>\n",
       "      <th>ITA</th>\n",
       "      <td>2644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lombardia</th>\n",
       "      <th>ITA</th>\n",
       "      <td>11685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veneto</th>\n",
       "      <th>ITA</th>\n",
       "      <td>1937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cases  death  recovered  tested\n",
       "city county state          country                                      \n",
       "NaN  NaN    NaN            Germany        3675    NaN       46.0     NaN\n",
       "                           Italy         17660    NaN     1439.0     NaN\n",
       "                           Spain          5232    NaN      193.0     NaN\n",
       "                           Switzerland    1139    NaN        4.0     NaN\n",
       "            Hubei          China         67786    NaN    51553.0     NaN\n",
       "            NaN            Iran          11364    NaN     2959.0     NaN\n",
       "                           Korea, South   7979    NaN      510.0     NaN\n",
       "            Guangdong      China          1356    NaN     1296.0     NaN\n",
       "            Henan          China          1273    NaN     1249.0     NaN\n",
       "            Zhejiang       China          1215    NaN     1197.0     NaN\n",
       "            Hunan          China          1018    NaN     1005.0     NaN\n",
       "            Emilia Romagna ITA            2644    NaN       54.0     NaN\n",
       "            Lombardia      ITA           11685    NaN     1660.0     NaN\n",
       "            Veneto         ITA            1937    NaN      107.0     NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"http://blog.lazd.net/coronadatascraper/data.csv\",parse_dates=True)\n",
    "dataCS =df.set_index([\"city\",\"county\",\"state\",\"country\"])\n",
    "\n",
    "\n",
    "#use index slice for more easy/clean access\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "IClmns= idx[\"cases\",\"death\",\"recovered\",\"tested\"]\n",
    "\n",
    "\n",
    "ctrMask = dataCS[\"cases\"] > 1000\n",
    "dataCS.loc[idx[:,:, :, ctrMask],IClmns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases in CA : 447 (does not match ca row)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cases</th>\n",
       "      <th>death</th>\n",
       "      <th>recovered</th>\n",
       "      <th>tested</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Mateo County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alameda County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sonoma County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Santa Cruz County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solano County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contra Costa County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stanislaus County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yolo County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sacramento County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fresno County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madera County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Placer County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shasta County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orange County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Riverside County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Diego County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ventura County</th>\n",
       "      <th>CA</th>\n",
       "      <th>USA</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = pd.IndexSlice\n",
    "\n",
    "# must have colons liberally used, firt two colons for city/county and last colon for all columns\n",
    "#option 1 for access\n",
    "dataCS.loc[(np.nan, \"Los Angeles County\", \"CA\", \"USA\")]\n",
    "#option 2 for access, using idx must have colons liberally used, firt two colons for city/county and last colon for all columns\n",
    "dataCS.loc[idx[:, \"San Diego County\", \"CA\", \"USA\"],IClmns]\n",
    "print(\"Total cases in CA : %d (does not match ca row)\"%dataCS.loc[idx[:, :, \"CA\", \"USA\"],:].sum()[\"cases\"])\n",
    "display(HTML(dataCS.loc[idx[:, :, \"CA\", \"USA\"],IClmns].to_html()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDC Data is here:\n",
    "\n",
    "html --> https://www.cdc.gov/coronavirus/2019-ncov/cases-in-us.html    \n",
    "json --> https://www.cdc.gov/coronavirus/2019-ncov/us-cases-epi-chart.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using cdc data direclty for the US\n",
    "\n",
    "\n",
    "url = \"https://www.cdc.gov/coronavirus/2019-ncov/us-cases-epi-chart.json\"\n",
    "\n",
    "r = requests.get(url)\n",
    "jdata =r.json()\n",
    "\n",
    "# get x/y's\n",
    "x = jdata[\"data\"][\"columns\"][0][1:]\n",
    "X = [datetime.datetime.strptime(d,\"%m/%d/%Y\").date() for d in x] # x's\n",
    "v = jdata[\"data\"][\"columns\"][1][1:] # v's (new cases fo the day)\n",
    "\n",
    "# interpolate the zeros, since nearly impossible to have no growth\n",
    "V = pd.Series(np.array(v).astype('int'))\n",
    "V[V==0]=np.nan #\n",
    "V = V.interpolate()\n",
    "if(0): #check data\n",
    "    print(list(zip(X,V)))\n",
    "# Remove fist zeros\n",
    "offsetZero = V.notna().idxmax()\n",
    "V = V.values[offsetZero:]\n",
    "X = X[offsetZero:]    \n",
    "\n",
    "# convert new cases (v) to cumulative cases(y)\n",
    "dataCdc = pd.Series(V,X).cumsum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# john hopkins data base\n",
    "## gui \n",
    "\n",
    "https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6\n",
    "\n",
    "## githunb \n",
    "\n",
    "https://github.com/CSSEGISandData/COVID-19\n",
    "\n",
    "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-46f51d6b64e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"%m/%d/%y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "URL = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/\"\n",
    "#      \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv\"\n",
    "\n",
    "files = [\"time_series_19-covid-Confirmed.csv\",\"time_series_19-covid-Deaths.csv\",\"time_series_19-covid-Recovered.csv\"]\n",
    "file = files[0]\n",
    "link =URL+file\n",
    "\n",
    "\n",
    "#read csv can read urls directly\n",
    "df = pd.read_csv(link,parse_dates=True)\n",
    "# set row indices, only have dates for columns ids\n",
    "df =df.set_index([\"Country/Region\",\"Lat\",\"Long\",\"Province/State\"])\n",
    "\n",
    "\n",
    "df.columns = pd.to_datetime(data.columns,format=\"%m/%d/%y\")\n",
    "\n",
    "dt = df.columns[-1]\n",
    "print(dt)\n",
    "if sum(df[dt].apply(math.isnan)):\n",
    "    print(\"missing samples go back one day\")\n",
    "    data = df.drop(columns=dt)\n",
    "else:\n",
    "    data = df\n",
    "#create a no china row, all china and all US\n",
    "\n",
    "#create a no china row, all china and all US\n",
    "noChin = data.index.levels[0][data.index.levels[0]!=\"China\"]\n",
    "euro      = [\"Germany\",\"DenMark\",\"France\",\"Italy\",\"Sweden\",\"Switzerland\",\n",
    "             \"Spain\",\"Portugal\",\"Belgium\",\"Iceland\",\"Ireland\",\"Netherlands\"]\n",
    "print(noChin)\n",
    "data.loc[\"NoChina\",np.NaN,np.NaN,np.NaN]=data.loc[(noChin)].sum()    \n",
    "data.loc[(\"Europe\",np.NaN,np.NaN,np.NaN)]=data.loc[euro].sum()    \n",
    "# note this is an over-estimate\n",
    "data.loc[(\"USAll\",np.NaN,np.NaN,np.NaN)]=data.loc[\"US\"].sum()    \n",
    "\n",
    "data.loc[(\"ChinaAll\",np.NaN,np.NaN,np.NaN)]=data.loc[\"China\"].sum()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new groups\n",
    "# dont use string for UR, but the 50 states\n",
    "\n",
    "northAmer = [\"US\",\"Canada\",\"Mexico\"],\n",
    "asia      = [\"South Korea\",\"Taiwan\",\"Japan\"]   \n",
    "middleEast=[\"Iraq\",\"Egypt\",\"Iran\"]\n",
    "countries={ \"NoChina\":\"NoChina\",\n",
    "            \"North America\":northAmer,\n",
    "            \"Europe\":\"Europe\",            \n",
    "            \"middle east\":middleEast,\n",
    "            \"China\":\"China\",\n",
    "            \"South Korea\":\"South Korea\",\n",
    "            \"Japan\":\"Japan\",\n",
    "            \"Italy\":\"Italy\",            \n",
    "            \"South Korea\":\"Korea, South\",\n",
    "            \"US\":\"US\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data.loc[\"Italy\"][dt]\n",
    "data[dt]# get last row\n",
    "data[data[dt]>1000].sort_values(\"Country/Region\").iloc[:,-5:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# create a model\n",
    "## use exponentia, until inflection point of logistic curve\n",
    "\n",
    "current count = previous count + E * p * previous count\n",
    "\n",
    "or \n",
    "\n",
    "current count = (1 + E * p) * previous count\n",
    "\n",
    "E = is average number of people someone infected is exposed to each day\n",
    "\n",
    "p = propabatiity of each exposed ecoming an infection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assume (1+E*P) is 120%\n",
    "\n",
    "\n",
    "#determine slope and plot\n",
    "for name in [\"NoChina\",\"China\", \"South Korea\", \"Europe\"]:\n",
    "    ctr = countries[name]\n",
    "    plt.figure()\n",
    "    vals= data.loc[ctr].sum().diff()\n",
    "    idx = np.argwhere(vals>0)[3][0]\n",
    "\n",
    "    #print(idx)\n",
    "    vals = vals[idx:]\n",
    "    lv = sp.log10(vals)\n",
    "    m=(max(lv)-lv[0])/(sp.size(lv))\n",
    "\n",
    "    print(\"Growth Rate %s:%.2f\"%(ctr,math.pow(10,m)))\n",
    "    #print()\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    #---\n",
    "    ax[1].plot(vals.index,pow(10,np.arange(0,sp.size(lv))*m+lv[0]))\n",
    "    ax[1].semilogy(vals)\n",
    "    ax[1].grid()\n",
    "#    ax[1].legend()\n",
    "    ax[1].xaxis.set_major_locator(myLocator)\n",
    "    ax[1].xaxis.set_major_formatter(myFmt)\n",
    "    ax[1].set_title(\"total cases over time\");\n",
    "\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    #---\n",
    "    y=data.loc[ctr].sum()\n",
    "    ax[0].plot_date(y.index,y.values)        \n",
    "    ax[0].grid()\n",
    "#    ax[0].legend()\n",
    "    ax[0].xaxis.set_major_locator(myLocator)\n",
    "    ax[0].xaxis.set_major_formatter(myFmt)\n",
    "    ax[0].set_title(\"total cases over time\");\n",
    "\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    fig.suptitle('%s'% name, fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ignore china here\n",
    "fig, ax =plt.subplots(1,2)\n",
    "for name in countries.keys():\n",
    "    if name ==\"China\":continue\n",
    "    country = countries[name]\n",
    "    y = data.loc[(country)].sum()\n",
    "    ax[0].plot(y.index,y.values,label=name)\n",
    "#ax[0].xaxis.set_major_locator(myLocator)\n",
    "ax[0].grid()\n",
    "ax[0].legend()\n",
    "ax[0].xaxis.set_major_locator(myLocator)\n",
    "ax[0].xaxis.set_major_formatter(myFmt)\n",
    "ax[0].set_title(\"total cases over time\");\n",
    "\n",
    "\n",
    "for name in countries.keys():\n",
    "    if name ==\"China\":continue\n",
    "    country = countries[name]\n",
    "    \n",
    "    vals= data.loc[(country)].sum().diff()\n",
    "    ax[1].plot(vals,label=name)\n",
    "ax[1].xaxis.set_major_locator(myLocator)\n",
    "ax[1].grid()\n",
    "ax[1].xaxis.set_major_formatter(myFmt)\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"new cases vs time\");\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smarter  model\n",
    "\n",
    "Y' = A * sech^2( B * (t-C) )\n",
    "\n",
    "Y = A/B * ( tanh( B * (t-C)) + 1 )\n",
    "\n",
    "[ The equation for Y is just the integral of the equation for Y', where I have set the constant of integration to make the curve start at zero cases so far. ]\n",
    "\n",
    "\n",
    "A = the peak infection rate (4600 case/day)\n",
    "\n",
    "B = the width parameter (0.116)\n",
    "\n",
    "C = the center date (2/6/2020 3AM)\n",
    "\n",
    "sech z = 1/cosh z\n",
    "\n",
    "       = 2/(e^z+e^-z)\n",
    "\n",
    "\n",
    " \n",
    "# references\n",
    "\n",
    "franklin antonio\n",
    "\n",
    "https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.1927.0118\n",
    "\n",
    " \n",
    "\n",
    "The Epidemic Curve parts I & II, Wilson & Burke, 1942,1943\n",
    "\n",
    "Proc Natl Acad Sci U S A. 1942 Sep; 28(9): 361–367\n",
    "\n",
    "Proc Natl Acad Sci U S A. 1943 Jan; 29(1): 43–48\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1078491/pdf/pnas01644-0025.pdf\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1078553/pdf/pnas01648-0050.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "filtV= \"South Korea\"\n",
    "filtV= \"Europe\"\n",
    "\n",
    "#filtV = \"US\"\n",
    "#filtV = \"Italy\"\n",
    "#filtV = \"China\"\n",
    "for ctr in countries.keys():\n",
    "    #only get filtered country or group, from countries dict\n",
    "    if not filtV == ctr: continue\n",
    "    \n",
    "    # get daily change, drop first value, '0'\n",
    "    Nd = data.loc[countries[ctr]].sum().diff().values[1:]\n",
    "    \n",
    "    A=max(Nd)\n",
    "    # this is width variable, smaller means slower groth (this is a guss)\n",
    "    # first run wiht a good set then adjust to target (for example run with south kora)\n",
    "    B=0.3\n",
    "\n",
    "    C=np.argmax(Nd)\n",
    "\n",
    "    # must be in days\n",
    "\n",
    "    t = np.arange(0,sp.size(Nd)+25)\n",
    "    fig, ax = plt.subplots(2,1,)\n",
    "    ax[0].plot(A/(np.cosh( B * (t-C))**2),label=\"model\")\n",
    "    ax[0].plot(Nd,label=ctr)\n",
    "    ax[1].grid()\n",
    "    ax[1].plot(A/B * ( np.tanh( B * (t-C)) + 1 ),label=\"model\")\n",
    "    ax[1].plot(data.loc[countries[ctr]].sum().values,label=ctr)\n",
    "    ax[1].grid()\n",
    "    plt.legend()\n",
    "    #plt.title(\"total cases over time\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align countries, with the following offset to get a prediction where they are \n",
    "# ideally normalize too\n",
    "\n",
    "offsets = {\"ChinaAll\":31,\n",
    "           \"Italy\":-9,\n",
    "           \"Spain\":-15,\n",
    "           \"Iran\":-8,\n",
    "           \"Germany\":-15,\n",
    "           \"Korea, South\":-5,\n",
    "           \"Switzerland\":-16,\n",
    "           \"France\":-15,\n",
    "           \"NoChina\":0,\n",
    "           \"Europe\":-5,\n",
    "           \"Norway\":-20,\n",
    "           \"United Kingdom\":-20,\n",
    "           \"USAll\":-20}\n",
    "\n",
    "\n",
    "                  \n",
    "\n",
    "\n",
    "#plt.rcParams['axes.prop_cycle'] = (\"cycler('color', 'rgbcmyk') +\"\n",
    "#                                   \"cycler('lw', [1, 1, 3])\")\n",
    "                  \n",
    "fig, ax=plt.subplots(1,1)\n",
    "for index, row in data[data[dt]>1000].iterrows():\n",
    "    ctr =index[0]\n",
    "    #print(ctr)\n",
    "    if(\"China\" == ctr): continue\n",
    "    \n",
    "    vdt = [(d +datetime.timedelta(days=offsets[ctr])).date()#.strftime(\"%m/%d\")\n",
    "           for d in data.columns]\n",
    "    \n",
    "    ax.plot(vdt,row.values, label=ctr)\n",
    "#ax.xaxis.set_major_locator(myLocator)\n",
    "ax.grid()\n",
    "#control range to zoom regio of interest\n",
    "ax.set_ylim(0, 10000)\n",
    "ax.set_xlim(datetime.date(2020, 2, 17), datetime.date.today())\n",
    "ax.xaxis.set_major_locator(myLocator)\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_formatter(myFmt)\n",
    "ax.legend()\n",
    "ax.set_title(\"new cases vs time\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try to predict the 'US' covid-19 number of illness, will adapt the rate, note this will only reflect\n",
    "# the positive exponent of the logistic curver (at the inflection points switchs from exponential to logarithmic)\n",
    "\n",
    "# assuming a groth rate of 10%\n",
    "#where will the us be\n",
    "#start date\n",
    "rate      = .20\n",
    "ctr       = \"US\"\n",
    "caseMin   = 300\n",
    "TN        = 21     # number of intervals after today\n",
    "\n",
    "\n",
    "\n",
    "s = data.loc[ctr].sum()\n",
    "startDate = s[s>caseMin].index[0]\n",
    "\n",
    "print(startDate)\n",
    "\n",
    "#nmber of intervals\n",
    "N  = sp.size(data.columns)\n",
    "\n",
    "\n",
    "# Set the epoch value\n",
    "Y0 = data[startDate][ctr].sum()\n",
    "#determine time offset\n",
    "offset = (data.columns[-1]-startDate).days\n",
    "Yt =Y0 * sp.exp(rate * np.arange(0,offset + TN))\n",
    "\n",
    "x = [startDate+datetime.timedelta(days=int(i)) for i in np.arange(0,offset + TN)]\n",
    "NE = (datetime.datetime.today()-data.columns[-1] ).days\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.plot_date(x,\n",
    "             Yt,\n",
    "             label=\"model\")\n",
    "\n",
    "\n",
    "\n",
    "ax.plot_date(x[:(offset+NE)],\n",
    "             data.loc[ctr,startDate:].sum(),\n",
    "             label=\"actual\")\n",
    "ax.xaxis.set_major_locator(myLocator)\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_formatter(myFmt)\n",
    "ax.legend()\n",
    "ax.set_title(\"projection:%s\"%ctr)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #try to predict the 'US' covid-19 number of illness, will adapt the rate, note this will only reflect\n",
    "# the positive exponent of the logistic curver (at the inflection points switchs from exponential to logarithmic)\n",
    "# use JHU\n",
    "# estimate US data\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "#find cumulateive greater then 50, this will be y0\n",
    "startDate = dataCdc[dataCdc>50].index[0]\n",
    "rate = .13\n",
    "\n",
    "#start from scratch take y[0] and assume X% groth and assume, y0 was 20% report of all reporting (multiply by 5)\n",
    "# get number of samples in the data base\n",
    "N = (datetime.date.today()-startDate).days\n",
    "\n",
    "#project for another 2 week\n",
    "NP = 20\n",
    "NEC = (datetime.date.today()    -dataCdc.index[-1]).days-1\n",
    "NEJ = (datetime.datetime.today()-data.columns[-1] ).days-1\n",
    "\n",
    "\n",
    "# project\n",
    "yh = dataCdc[startDate] * 5 * np.exp(rate * np.arange(0,N+NP))\n",
    "\n",
    "x = [startDate+datetime.timedelta(days=int(i)) for i in np.arange(0,N+NP)]\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.plot_date(x,\n",
    "             yh,\n",
    "             label=\"model\")\n",
    "ax.plot_date(x[0:(N-NEC)],\n",
    "             dataCdc[startDate:].values,\n",
    "             label=\"actual-CDC\")\n",
    "ax.plot_date(x[0:(N-NEJ)],\n",
    "             data.loc[\"US\",startDate:].sum().values,\n",
    "             label=\"actual-JHU\")\n",
    "ax.plot_date(datetime.date.today(),\n",
    "             dataCS.loc[idx[:, :, :, \"USA\"],\"cases\"].sum(),\n",
    "            label=\"3rd source\")\n",
    "\n",
    "ax.xaxis.set_major_locator(myLocator)\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_formatter(myFmt)\n",
    "ax.legend()\n",
    "ax.set_title(\"model vs observed\")\n",
    "\n",
    "\n",
    "yc = np.concatenate([dataCdc.loc[startDate:].values,\n",
    "                     np.nan * np.ones(NP+NEC)])\n",
    "\n",
    "\n",
    "yj = np.concatenate([data.loc[\"US\",startDate:].sum().values,\n",
    "                    np.nan * np.ones(NP+NEJ)])\n",
    "\n",
    "\n",
    "if(1):\n",
    "    df =pd.DataFrame({\"model\": yh,\n",
    "                  \"cdc\"  : yc,\n",
    "                  \"jhu\"  : yj},index=x)\n",
    "    print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script for scraping HTML sites but does not work on java scripts, need to inspect and find source\n",
    "import requests\n",
    "try:\n",
    "    from bs4 import BeautifulSoup\n",
    "except ImportError:\n",
    "    !pip install packaging\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "URL = 'https://www.cdc.gov/coronavirus/2019-ncov/cases-in-us.html'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#notes on soup are here: https://realpython.com/beautiful-soup-web-scraper-python/\n",
    "#print(soup.prettify())\n",
    "#res = soup.find(\"epi-curve\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# JHNU - usa has a problem cities and states overlap\n",
    "usStates=\"\"\"\n",
    "Alabama\n",
    "Alaska\n",
    "Arizona\n",
    "Arkansas\n",
    "California\n",
    "Colorado\n",
    "Connecticut\n",
    "Delaware\n",
    "Florida\n",
    "Georgia\n",
    "Hawaii\n",
    "Idaho\n",
    "Illinois\n",
    "Indiana\n",
    "Iowa\n",
    "Kansas\n",
    "Kentucky\n",
    "Louisiana\n",
    "Maine\n",
    "Maryland\n",
    "Massachusetts\n",
    "Michigan\n",
    "Minnesota\n",
    "Mississippi\n",
    "Missouri\n",
    "Montana\n",
    "Nebraska\n",
    "Nevada\n",
    "New Hampshire\n",
    "New Jersey\n",
    "New Mexico\n",
    "New York\n",
    "North Carolina\n",
    "North Dakota\n",
    "Ohio\n",
    "Oklahoma\n",
    "Oregon\n",
    "Pennsylvania\n",
    "Rhode Island\n",
    "South Carolina\n",
    "South Dakota\n",
    "Tennessee\n",
    "Texas\n",
    "Utah\n",
    "Vermont\n",
    "Virginia\n",
    "Washington\n",
    "West Virginia\n",
    "Wisconsin\n",
    "Wyoming\n",
    "\"\"\"\n",
    "\n",
    "US = usStates.split('\\n')[1:-1]\n",
    "#data.loc[(US)]\n",
    "sp.size(US)\n",
    "#usStates.split('\\n')[1:-1]\n",
    "#US = list(set(data.index.levels[3])&set(US))\n",
    "print(data.loc[(\"US\",slice(None),slice(None),US)].sum()[-1])\n",
    "print(data.loc[\"US\"].sum()[-1])\n",
    "#data.filter(like=',',axis=0)\n",
    "#data.loc[\"US\"]\n",
    "#data.loc[\"US\"]\n",
    "#data.loc[(\"US\",slice(None),slice(None), lambda df.: df.index.levels[3].str.contains(','))]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
